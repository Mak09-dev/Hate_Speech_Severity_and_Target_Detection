# ðŸ§  Evaluating Traditional ML Models vs Transformer Architectures for Hate Speech Detection

## ðŸ“Œ Overview

This project presents a comparative analysis between **traditional machine learning models** â€” *Logistic Regression (LR)* and *Multinomial Naive Bayes (MNB)* â€” and a **Transformer-based architecture (DistilBERT)** for multi-stage **hate speech detection** using the OLID dataset.
The goal is to evaluate how **deep contextual embeddings** improve classification accuracy and contextual understanding compared to conventional feature-based approaches.

---

## ðŸŽ¯ Problem Statement

Social media platforms like Twitter and Facebook have led to an exponential increase in user-generated content, including hate speech and offensive remarks. Manual moderation is infeasible at scale.

To address this, a **two-stage hate speech detection pipeline** was developed:

1. **Stage 1:** Detect *Offensive* vs *Non-Offensive* tweets.
2. **Stage 2A:** For offensive tweets, classify as *Targeted* (TIN) or *Untargeted* (UNT).
3. **Stage 2B:** For targeted tweets, identify target type â€” *Individual (IND)*, *Group (GRP)*, or *Others (OTH)*.

---

## ðŸ§¾ Dataset

**Dataset Used:** [OLID â€“ Offensive Language Identification Dataset (Kaggle)](https://www.kaggle.com/datasets/olid)

| Stage                | Labels                             | Count                  | Observation                              |
| -------------------- | ---------------------------------- | ---------------------- | ---------------------------------------- |
| Stage 1 (Subtask A)  | NOT: 8,840 / OFF: 4,400            | Moderately imbalanced  | Twice as many non-offensive samples      |
| Stage 2A (Subtask B) | TIN: 3,876 / UNT: 524              | Highly imbalanced      | Majority offensive tweets are targeted   |
| Stage 2B (Subtask C) | IND: 2,407 / GRP: 1,074 / OTH: 395 | Complex class overlaps | Most offensive tweets target individuals |

Preprocessing involved cleaning tweets (removing URLs, mentions, hashtags, special symbols), converting to lowercase, and applying **minority class upsampling** to balance training.

---

## âš™ï¸ Methodology

### ðŸ”¹ Traditional Machine Learning Models

* **Logistic Regression (LR):** TF-IDF feature-based linear model.
* **Multinomial Naive Bayes (MNB):** Word-frequency-based probabilistic classifier.

**Workflow:**
`Text â†’ TF-IDF Vectorization â†’ Classifier (LR/MNB) â†’ Output`

### ðŸ”¹ Transformer Model â€“ DistilBERT

A compact version of BERT retaining ~97% of performance while being faster and lighter. Fine-tuned individually for each stage.

**Workflow:**
`Text â†’ Tokenizer â†’ DistilBERT Encoder â†’ Classification Layer â†’ Output`

### ðŸ§® Evaluation Metrics

* Accuracy
* Macro & Weighted Precision, Recall, F1-score

---

## ðŸ“Š Results and Analysis

| **Stages**   | **Models**     | **Macro Averaging** |            |          | **Weighted Averaging** |            |          | **Accuracy** |
| ------------ | -------------- | ------------------- | ---------- | -------- | ---------------------- | ---------- | -------- | ------------ |
|              |                | **Precision**       | **Recall** | **F1**   | **Precision**          | **Recall** | **F1**   |              |
| **Stage-1**  | LG             | 0.66                | 0.67       | 0.66     | 0.70                   | 0.69       | 0.69     | 0.69         |
|              | MNB            | 0.66                | 0.66       | 0.66     | 0.70                   | 0.70       | 0.70     | 0.70         |
|              | **DistilBERT** | **0.74**            | **0.75**   | **0.75** | **0.78**               | **0.77**   | **0.77** | **0.77**     |
| **Stage-2A** | LG             | 0.56                | 0.56       | 0.56     | 0.82                   | 0.82       | 0.82     | 0.82         |
|              | MNB            | **0.60**            | 0.53       | 0.53     | 0.82                   | **0.87**   | **0.83** | **0.87**     |
|              | DistilBERT     | 0.55                | 0.53       | 0.53     | 0.80                   | 0.84       | 0.82     | 0.84         |
| **Stage-2B** | LG             | 0.52                | 0.52       | 0.52     | 0.67                   | 0.66       | 0.66     | 0.66         |
|              | MNB            | 0.45                | 0.47       | 0.45     | 0.62                   | 0.66       | 0.64     | 0.66         |
|              | **DistilBERT** | **0.54**            | **0.55**   | **0.54** | **0.69**               | **0.69**   | **0.69** | **0.69**     |

---

## ðŸ” Comparative Insights

* **DistilBERT** consistently achieved superior contextual understanding and overall accuracy.
* **Stage 1:** Highest Macro F1 = 0.75, Accuracy = 0.77.
* **Stage 2A:** MNB slightly led due to clear lexical patterns (Accuracy = 0.87).
* **Stage 2B:** DistilBERT again led (Macro F1 = 0.54, Accuracy = 0.69).
* **Conclusion:** Transformers excel at context-based hate speech detection, while traditional models remain efficient for simpler, interpretable tasks.

---

## ðŸ§© Repository Structure

```
â”œâ”€â”€ LG AND MNB Implementation.ipynb   # Logistic Regression & Naive Bayes models
â”œâ”€â”€ DistilBERT Implementation.ipynb    # Transformer fine-tuning & evaluation
â”œâ”€â”€ GRP-13-MTECH.pdf                   # Detailed project report
â””â”€â”€ README.md                          # Documentation file
```

---

## ðŸ§  Conclusion

DistilBERT achieved the **best trade-off between accuracy and contextual comprehension**, capturing subtle and implicit hate speech patterns.
Logistic Regression offered **interpretability and consistency**, while Naive Bayes proved **efficient for lightweight text classification**.
Together, they form a balanced approach for scalable and explainable **hate speech detection systems**.

---

## ðŸ‘¥ Authors

**Group 13 â€“ CS683 Project (IIIT Guwahati)**

* Mayank Singh (2402055)
* Nishant Kashyap (2402063)
* Shreya Ghosh (2402029)
* Hrishiraj Sawan (2402012)
* Sunidhi Choudhary (2402035)

**Project Guide:** *Dr. Kuntal Dey*
Department of Computer Science & Engineering
Indian Institute of Information Technology, Guwahati

---

## âš™ï¸ Tech Stack

* Python (scikit-learn, pandas, numpy)
* Hugging Face Transformers (DistilBERT)
* Jupyter Notebook
* Kaggle OLID Dataset

---

## ðŸ“š Citation

> Group 13 (2025). *Evaluating Traditional ML Models against Transformer Architectures for Hate Speech Severity and Target Detection.* IIIT Guwahati, India.
